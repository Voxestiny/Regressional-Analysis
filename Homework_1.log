---------------------------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  C:\Users\soulu\OneDrive - University of Toronto\University of Toronto\UTM 2021-2023\7_2023 Fall\ECO375H5F\Homework\Homewor
> k 1\Homework_1.log
  log type:  text
 opened on:  16 Oct 2023, 01:31:54

. do "C:\Users\soulu\AppData\Local\Temp\STD5d8c_000000.tmp"

. ********************************************************************************
. **************** ECO375 Homework 1 (Cheong Siu Lun, Chris) *********************
. ********************************************************************************
. 
. 
. // Setting up Working Directory
. cd "C:\Users\soulu\OneDrive - University of Toronto\University of Toronto\UTM 2021-2023\7_2023 Fall\ECO375H5F\Homework\Homework 1"
C:\Users\soulu\OneDrive - University of Toronto\University of Toronto\UTM 2021-2023\7_2023 Fall\ECO375H5F\Homework\Homework 1

. use "eco375hw1data2023", clear

. 
. 
. *****************************
. // Question 4: Google Trends
. *****************************
. // (a) Present a table showing the mean and standard deviation of normalized search interest in each city name in the data set.
. 
. describe

Contains data from eco375hw1data2023.dta
 Observations:            13                  
    Variables:            14                  27 Sep 2023 13:30
---------------------------------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
---------------------------------------------------------------------------------------------------------------------------------------
location        str25   %25s                  
montreal        byte    %10.0g                
umbrella        byte    %10.0g                
vancouver       byte    %10.0g                
toronto         byte    %10.0g                
pizza           byte    %10.0g                
ice_cream       byte    %10.0g                
cloud           byte    %10.0g                
boots           byte    %10.0g                
poutine         byte    %10.0g                
warm            byte    %10.0g                
cold            byte    %10.0g                
snow            byte    %10.0g                
rain            byte    %10.0g                
---------------------------------------------------------------------------------------------------------------------------------------
Sorted by: location

. summarize montreal vancouver toronto

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
    montreal |         13    13.53846    26.13623          3        100
   vancouver |         13    12.46154    26.96793          2        100
     toronto |         13    19.53846    24.46976          7        100

. 
. /* 
> Since with the code "describe", we notice that there are 3 city names displayed, therefore we can use the code "summarize montreal va
> ncouver toronto" to display a table summarizing the mean of standard deviation (sd) of each city name. Hence, the results are as foll
> ow:
> 1. montreal
>         mean = 13.53846
>         sd = 26.13623
> 2. vancouver
>         mean = 12.46154
>         sd = 26.96793
> 3. toronto
>         mean = 19.53846
>         sd = 24.46976
> */
. 
. 
. // (b) Use OLS to estimate β1 in: rain = β0 + β1umbrella + u. Report the estimate β_1 hat in words a non-economist could understand. 
> Do not use causal language. Should we think of this as an estimate of the causal effect of searches for umbrellas on searches for rai
> n? Why or why not?
. 
. regress rain umbrella

      Source |       SS           df       MS      Number of obs   =        13
-------------+----------------------------------   F(1, 11)        =      8.28
       Model |  1263.46567         1  1263.46567   Prob > F        =    0.0150
    Residual |  1678.84202        11  152.622002   R-squared       =    0.4294
-------------+----------------------------------   Adj R-squared   =    0.3775
       Total |  2942.30769        12  245.192308   Root MSE        =    12.354

------------------------------------------------------------------------------
        rain | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
    umbrella |    .627965   .2182541     2.88   0.015     .1475911    1.108339
       _cons |   34.01729    16.0835     2.12   0.058    -1.382269    69.41684
------------------------------------------------------------------------------

. matrix list e(b)

e(b)[1,2]
     umbrella      _cons
y1  .62796504  34.017286

. 
. /* 
> The code "regress rain umbrella" constructs a simple linear regression analysis with dependent variable (y) as rain and explanatory v
> ariable (x) as unbrella. We can display the matrix of coefficient estimates with the code "matrix list e(b)". Here, we can see that b
> eta 1 hat is 0.62796504. This implies that for every 1 unit increase in the normalized search interest of "umbrella", there is a 0.62
> 796504 unit increase in the normalized search interest of "rain". 
> 
> No, we should not think this as an estimate of the causal effect between searches of unbrellas and rain. The reason is that beta 1 ha
> t in this case only implies a positive correlation and correlation is not equivalent to causality. There may be omitted variables, re
> verse causality, or even endogeneity that disagrees with the hypothesis of causality of rain and umbrella. In other words, we do not 
> have enough information to conclude causality with only beta 1 hat.
> */
. 
. 
. // (c) Create a new variable, aboveavgcold, that is equal to 1 if the location has normalized search interest above that variable's a
> verage, and 0 otherwise. Use a regression to estimate the difference between normalized search interest for pizza when normalized sea
> rch interest for cold is above or below average. Is this difference significantly different from 0 at the 5% level?
. 
. egen cold_mean = mean(cold)

. gen aboveavgcold = 0

. replace aboveavgcold = 1 if cold > cold_mean
(8 real changes made)

. reg pizza aboveavgcold

      Source |       SS           df       MS      Number of obs   =        13
-------------+----------------------------------   F(1, 11)        =      0.24
       Model |  96.4923077         1  96.4923077   Prob > F        =    0.6344
    Residual |      4437.2        11  403.381818   R-squared       =    0.0213
-------------+----------------------------------   Adj R-squared   =   -0.0677
       Total |  4533.69231        12  377.807692   Root MSE        =    20.084

------------------------------------------------------------------------------
       pizza | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
aboveavgcold |        5.6   11.44985     0.49   0.634    -19.60095    30.80095
       _cons |       72.4   8.982002     8.06   0.000     52.63075    92.16925
------------------------------------------------------------------------------

. 
. /* 
> Step 1: egen cold_mean = mean(cold)
> This code generates a new column with the average value of the normalized search interest of "cold" in every entry.
> 
> Step 2: gen aboveavgcold = 0
> This code creates a new variable "aboveavgcold" and input all entries with 0 initially.
> 
> Step 3: replace aboveavgcold = 1 if cold > cold_mean
> This code replaces the entries of aboveavgcold if it satisfies the condition the value of cold is greater than that of cold_mean.
> 
> Step 4: reg pizza aboveavgcold
> This code performs an ols regression on a binary explanatory variable. The estimate of beta 1 hat in the result is 5.6. This value is
>  the estimate of the treatment effect, i.e. te_i = y_i(1)-y_i(0). Since the p-value is 0.634 > 0.05 (significant level), we fail to r
> eject the null hypothesis (H0), i.e. the difference between y(1) and y(0) is not significantly different from 0 (beta 1 = te = 0).
> */
. 
. 
. // (d) Use OLS to estimate β1 in each of the following equations. Report your estimate for each using words a non-economist could und
> erstand. Use causal language for this part (even though the results may not actually be causal).
. /* 
> poutine = β0 + β1 ln(montreal) + u
> ln(poutine) = β0 + β1montreal + u
> ln(poutine) = β0 + β1 ln(montreal) + u
> */
. 
. gen montreal_ln = ln(montreal)

. gen poutine_ln = ln(poutine)

. reg poutine montreal_ln

      Source |       SS           df       MS      Number of obs   =        13
-------------+----------------------------------   F(1, 11)        =     31.11
       Model |  4389.14202         1  4389.14202   Prob > F        =    0.0002
    Residual |  1551.78106        11  141.071006   R-squared       =    0.7388
-------------+----------------------------------   Adj R-squared   =    0.7151
       Total |  5940.92308        12  495.076923   Root MSE        =    11.877

------------------------------------------------------------------------------
     poutine | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 montreal_ln |    20.5043   3.675987     5.58   0.000     12.41351    28.59509
       _cons |   -10.1444   7.902576    -1.28   0.226    -27.53785    7.249055
------------------------------------------------------------------------------

. reg poutine_ln montreal

      Source |       SS           df       MS      Number of obs   =        13
-------------+----------------------------------   F(1, 11)        =     26.71
       Model |  2.04324557         1  2.04324557   Prob > F        =    0.0003
    Residual |  .841432366        11  .076493851   R-squared       =    0.7083
-------------+----------------------------------   Adj R-squared   =    0.6818
       Total |  2.88467794        12  .240389828   Root MSE        =    .27658

------------------------------------------------------------------------------
  poutine_ln | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
    montreal |    .015788   .0030548     5.17   0.000     .0090645    .0225115
       _cons |   3.040751   .0871467    34.89   0.000     2.848943     3.23256
------------------------------------------------------------------------------

. reg poutine_ln montreal_ln

      Source |       SS           df       MS      Number of obs   =        13
-------------+----------------------------------   F(1, 11)        =     17.56
       Model |  1.77362389         1  1.77362389   Prob > F        =    0.0015
    Residual |  1.11105405        11  .101004914   R-squared       =    0.6148
-------------+----------------------------------   Adj R-squared   =    0.5798
       Total |  2.88467794        12  .240389828   Root MSE        =    .31781

------------------------------------------------------------------------------
  poutine_ln | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 montreal_ln |    .412179   .0983618     4.19   0.002     .1956862    .6286718
       _cons |   2.449057   .2114565    11.58   0.000     1.983644    2.914469
------------------------------------------------------------------------------

. 
. /* 
> Step 1: gen montreal_ln = ln(montreal) & gen poutine_ln = ln(poutine)
> These 2 codes generate a new variable by taking the natural logrithm of the variable inside the ln() function.
> 
> Step 2: reg y x; where y = poutine or poutine_ln and x = montreal or montreal_ln
> This code runs an ols regression on the specified dependent and explanatory variables subject to the question.
> 
> 1. For poutine = β0 + β1 ln(montreal) + u
> code: reg poutine montreal_ln
> Here, we can see that the beta 1 hat is 20.5043. This implies that for every 1% increase in the normalized search interest in "montre
> al", there is a 0.01*20.5043 = 0.205043 unit increase in the normalized search interest of "poutine".
> 
> 2. For ln(poutine) = β0 + β1montreal + u
> code: reg poutine_ln montreal
> Here, we can see that the beta 1 hat is 0.015788. This implies that for every 0.01 unit increase in the normalized search interest in
>  "montreal", there is a 0.015788% increase in the normalized search interest of "poutine".
> 
> 3. For reg poutine_ln montreal_ln
> code: reg poutine_ln montreal_ln
> Here, we can see that the beta 1 hat is 0.412179. This implies that for every 1% increase in the normalized search interest in "montr
> eal", there is a 0.412179% increase in the normalized search interest of "poutine".
> */
. 
. 
. // (e) Using the data, briefly present and describe one fact that you think is interesting. Your answer to this question must actuall
> y use Stata code and the data to find a fact that was not discussed in a previous question.
. 
. twoway (scatter poutine montreal_ln) (lowess poutine montreal_ln)

. graph export "Q4e_poutine montreal_ln.pdf", replace
file Q4e_poutine montreal_ln.pdf saved as PDF format

. twoway (scatter poutine_ln montreal) (lowess poutine_ln montreal)

. graph export "Q4e_poutine_ln montreal.pdf", replace
file Q4e_poutine_ln montreal.pdf saved as PDF format

. twoway (scatter poutine_ln montreal_ln) (lowess poutine_ln montreal_ln)

. graph export "Q4e_poutine_ln montreal_ln.pdf", replace
file Q4e_poutine_ln montreal_ln.pdf saved as PDF format

. 
. /*
> The above codes create a layered graph of scatter plot and lowess plot. We can see that from the graphs generated, "poutine_ln montre
> al_ln.pdf" seems to have a better overall linear relationship than the other 2 graphs. In this case, using poutine_ln and montreal_ln
>  seems to be the best variables (logrithm transformation) to run an ols regression on.
> */
. 
. 
. 
. *****************************
. // Question 5: Monte Carlo Simulation
. *****************************
. // (a) Simulate the model once in Stata. Generate a data set {yi, xi: i = 1, ..., n} with n = 400 observations. Show a scatterplot of
>  X and Y . Use OLS to estimate β0 and β1; what are your estimates?
. 
. // Step 1: Clear Working Directory and Set Seed
. clear all

. set seed 123

. 
. // Step 2: Create Simulation Program "rg_5a"
. cap program drop rg_5a

. program rg_5a, rclass
  1. drop _all
  2. set obs 400
  3. gen x = rnormal(-1,1)
  4. gen u = rnormal(0,1)
  5. gen y = 2 + 3*x + u
  6. qui regress y x
  7. return scalar b0_5a = _b[_cons]
  8. return scalar b1_5a = _b[x]
  9. end

. 
. // Step 3: Simulate rg_5a with 1 Repitition to Estimate β0 and β1
. simulate "rg_5a" b0_5a = r(b0_5a) b1_5a = r(b1_5a), reps(1)

Command:      rg_5a
Statistics:   b0_5a      = r(b0_5a)
              b1_5a      = r(b1_5a)

. di b0_5a 
2.1037087

. di b1_5a
3.0248418

. 
. // Step 4: Construct Scatterplot of x and y with the Same Seed 123
. set seed 123

. set obs 400
Number of observations (_N) was 1, now 400.

. gen x = rnormal(-1,1) //generate variable x

. gen u = rnormal(0,1)  //generate variable u

. gen y = 2 + 3*x + u   //generate variable y

. scatter y x, title("Scatterplot of X and Y")

. graph export "Q5a_Scatterplot of X and Y.pdf", replace
file Q5a_Scatterplot of X and Y.pdf saved as PDF format

. 
. /*
> 1. Generate a data set {yi, xi: i = 1, ..., n} with n = 400 observations
> Since we will be using the same seed "seed 123", this psuedo-random number generator starting point will ensure us to be obtaining th
> e same results in both the simulation program "rg_5a" and the one run in Step 4 above.
> 
> - code: set seed 123
> This code set the same seed for both rg_5a and Step 4
> 
> - code: set obs 400
> This code set the number of observations to be taken from the random number generator to be 400.
> 
> - codes: gen x = rnormal(-1,1) ; gen u = rnormal(0,1) ; gen y = 2 + 3*x + u 
> These codes generate the required data frame containing {yi, xi}. We can see that x follows a normal distrubution with mean=-1 and st
> andard deviation=1, while u follows a normal distribution with mean=0 and standard deviation=1.
> 
> 2. Show scatterplot of X and Y
> - code: scatter y x, title("Scatterplot of X and Y")
> This code creates a scatterplot with y on the Y-axis and x on the X-axis.
> 
> -code: graph export "Q5a_Scatterplot of X and Y.pdf", replace
> This code exports a pdf version of the graph and will replace the graph every time the code is run.
> 
> 3. Simulate the model once and use ols to estimate β0 and β1
> In step 2, we created a program named "rg_5a" to run the simulations n times. Since the question is asking to simulate once only, the
> refore n=1 (i.e. reps(1)). In the program, we would follow the same intuition as the above parts by setting seed and creating the var
> iables x, y and u with 400 observations. Then, we will regress y against x, returning the beta 0 hat and beta 1 hat in scalar form be
> fore ending the program.
> 
> - code: simulate "rg_5a" b0_5a = r(b0_5a) b1_5a = r(b1_5a), reps(1)
> This code simulates the program "rg_5a" and store b0_5a as b0_5a and b1_5a as b1_5a.
> 
> - code: di b0_5a ; di b1_5a
> These 2 codes return the beta 0 hat and beta 1 hat of the program with 1 repetition. The beta 0 hat is 2.1037087, and the beta 1 hat 
> is 3.0248418
> */
. 
. 
. // (b) Now, simulate this model 200 times in Stata. For each simulation, generate adata set {yi, xi: i = 1, ..., n} with n = 200 obse
> rvations. Then, for each sample, estimate β0 and β1 using OLS and save the results βˆ0 and βˆ1. What are the averages and the standar
> d deviations of βˆ0 and βˆ1 across the simulations? Are βˆ0 and βˆ1 close to the true β0 and β1? Why should we expect that result? Pl
> ot the histograms of βˆ0 and βˆ1.
. 
. // Step 1: Clear Working Directory and Set Seed
. clear all

. set seed 123

. 
. // Step 2: Create Simuation Program "rg_5b"
. cap program drop rg_5b

. program rg_5b, rclass
  1. drop _all
  2. set obs 200
  3. gen x = rnormal(-1,1)
  4. gen u = rnormal(0,1)
  5. gen y = 2 + 3*x + u
  6. qui regress y x
  7. return scalar b0_5b = _b[_cons]
  8. return scalar b1_5b = _b[x]
  9. end

. 
. // Step 3: Simulate rg_5b 200 times
. simulate "rg_5b" b0_5b = r(b0_5b) b1_5b = r(b1_5b), reps(200)

Command:      rg_5b
Statistics:   b0_5b      = r(b0_5b)
              b1_5b      = r(b1_5b)

. 
. // Step 4: Find the Averages and Standard Deviations of Beta 0 Hat and Beta 1 Hat
. summarize b0_5b, detail

                          r(b0_5b)
-------------------------------------------------------------
      Percentiles      Smallest
 1%     1.776335       1.759931
 5%     1.833387       1.769476
10%     1.876199       1.783194       Obs                 200
25%      1.92395       1.794756       Sum of wgt.         200

50%     1.987072                      Mean           1.994573
                        Largest       Std. dev.      .0992975
75%     2.054055       2.203185
90%      2.12197       2.205359       Variance         .00986
95%      2.17638        2.24461       Skewness       .2643897
99%     2.224984       2.310304       Kurtosis       2.939141

. summarize b1_5b, detail

                          r(b1_5b)
-------------------------------------------------------------
      Percentiles      Smallest
 1%     2.824616       2.795084
 5%     2.879355       2.820245
10%     2.902719       2.828988       Obs                 200
25%     2.942472       2.839971       Sum of wgt.         200

50%     2.992285                      Mean            2.99587
                        Largest       Std. dev.      .0758896
75%     3.047745       3.172851
90%     3.093794       3.175275       Variance       .0057592
95%     3.120811       3.192064       Skewness       .1254685
99%     3.183669       3.197362       Kurtosis       2.781746

. 
. // Step 5: Plot the Hitograms of Both Beta 0 Hat and Beta 1 Hat
. hist b0_5b, normal
(bin=14, start=1.7599306, width=.0393124)

. graph export "Q5b_b0_5b.pdf", replace
file Q5b_b0_5b.pdf saved as PDF format

. hist b1_5b, normal
(bin=14, start=2.7950835, width=.02873417)

. graph export "Q5b_b1_5b.pdf", replace
file Q5b_b1_5b.pdf saved as PDF format

. 
. /*
> From Step 4, we can see that results as follow:
> 1. Beta 0 Hat (b0_5b)
> - Average/Mean: 1.994573
> - Standard Deviation: 0.0992975
> 
> 2. Beta 1 Hat (b_1_5b)
> - Average/Mean: 2.99587
> - Standard Deviation: 0.0758896
> 
> Yes, the beta 0 hat and beta 1 hat this time are closer to the true beta 0 and beta 1 than that estimated in 5a. The reason is that e
> ven though we reduced the number of observations for each regression from 400 to 200, however, 5a only performed 1 regression whereas
>  5b performed 200 regressions and obtained 200 estimates of beta 0 hat and beta 1 hat. Therefore, by law of large numbers, the distri
> bution of both beta 0 hat and beta 1 hat will coverge normally to the true beta 0 and beta 1 where the averages obtained as n increas
> es will converge in probability to the true parameters; this is supported by the diminishing variance/standard deviation of both beta
>  0 hat and beta 1 hat.
> */
. 
. 
. // (c) With a bit of algebra, we can see that X = −2/3 + 1/3*Y − 1/3*U. Now, again simulate the same model as above (Y = β0+β1X+U), 2
> 00 times, and for each simulation, generate a data set {yi, xi: i = 1, ..., n} with n = 400 observations. This time, though, you shou
> ld use OLS to estimate γ0 and γ1 in the regression X = γ0 + γ1Y + V . (That is, regression X against Y rather than the other way arou
> nd.) What are the averages and standard deviations of ˆγ0 and ˆγ1, the OLS estimates? Are ˆγ0 and ˆγ1 usually close to −2/3 and 1/3? 
> Why should we expect that result?
. 
. // Step 1: Clear Working Directory and Set Seed
. clear all

. set seed 123

. 
. // Step 2: Create Simuation Program "rg_5c"
. cap program drop rg_5b

. program rg_5c, rclass
  1. drop _all
  2. set obs 400
  3. gen x = rnormal(-1,1)
  4. gen u = rnormal(0,1)
  5. gen y = 2 + 3*x + u
  6. qui regress x y
  7. return scalar b0_5c = _b[_cons]
  8. return scalar b1_5c = _b[y]
  9. end

. 
. // Step 3: Simulate rg_5c 200 times
. simulate "rg_5c" b0_5c = r(b0_5c) b1_5c = r(b1_5c), reps(200)

Command:      rg_5c
Statistics:   b0_5c      = r(b0_5c)
              b1_5c      = r(b1_5c)

. 
. // Step 4: Find the Averages and Standard Deviations of Gamma 0 Hat and Gamma 1 Hat
. summarize b0_5c, detail

                          r(b0_5c)
-------------------------------------------------------------
      Percentiles      Smallest
 1%    -.7365149      -.7377384
 5%    -.7287371      -.7374994
10%    -.7240078      -.7355305       Obs                 200
25%    -.7146951      -.7341434       Sum of wgt.         200

50%    -.7014662                      Mean          -.7008598
                        Largest       Std. dev.      .0176378
75%    -.6874737      -.6676232
90%    -.6749993      -.6670183       Variance       .0003111
95%    -.6716495      -.6669806       Skewness        .125705
99%    -.6669994      -.6513506       Kurtosis        2.35149

. summarize b1_5c, detail

                          r(b1_5c)
-------------------------------------------------------------
      Percentiles      Smallest
 1%     .2874992       .2867582
 5%     .2907877       .2868733
10%     .2928057       .2881252       Obs                 200
25%     .2963146       .2884414       Sum of wgt.         200

50%     .2996316                      Mean           .2993803
                        Largest       Std. dev.      .0050753
75%     .3029196       .3109228
90%     .3051328       .3125116       Variance       .0000258
95%      .307262       .3125918       Skewness      -.0055141
99%     .3125517       .3136923       Kurtosis        3.05387

. mean b0_5c

Mean estimation                            Number of obs = 200

--------------------------------------------------------------
             |       Mean   Std. err.     [95% conf. interval]
-------------+------------------------------------------------
       b0_5c |  -.7008598   .0012472     -.7033192   -.6984004
--------------------------------------------------------------

. mean b1_5c

Mean estimation                            Number of obs = 200

--------------------------------------------------------------
             |       Mean   Std. err.     [95% conf. interval]
-------------+------------------------------------------------
       b1_5c |   .2993803   .0003589      .2986726     .300088
--------------------------------------------------------------

. 
. /*
> From Step 4, we can see that results as follow:
> 1. Gamma 0 Hat (b0_5c)
> - Average/Mean: -0.7008598
> - Standard Deviation: 0.0176378
> 
> 2. Gamma 1 Hat (b_1_5c)
> - Average/Mean: 0.2993803
> - Standard Deviation: 0.0050753
> 
> From codes: mean b0_5c and mean b1_5c, we can see that the 95% confidence interval for gamma 0 hat is [-0.7033192, -0.6984004], while
>  the 95% confidence interval for gamma 1 hat is [0.2986726, 0.300088]. We can see that both the true value of gamma 0 (-0.666667) and
>  gamma 1 (0.3333333) fall beyond their respective confidence intervals. This implies that we have to reject the null hypothesis given
>  the model, i.e. the estimators for gamma 0 and gamma 1 are biased. The reason for this is because the ols regression consists of an 
> error term u in which u captures the unexplained variation which are independent of x but not y. Reversing the dependent and independ
> ent variable in the regression does not reverse the dependency of u and E[u|x]=0 does not imply E[u|y]=0 as y originally is a functio
> n of x and u. Therefore, running a regression of x against y will likely result in a biased estimation on gamma 0 and gamma 1, as cor
> r(y,u)=corr(2+3*x+u,u)=corr(u,u)=1, which is not 0. This violates SLR.4: expectation of u conditioned on the independent variable (in
>  this case y) is 0.
> */
. 
. 
end of do-file

. log close
      name:  <unnamed>
       log:  C:\Users\soulu\OneDrive - University of Toronto\University of Toronto\UTM 2021-2023\7_2023 Fall\ECO375H5F\Homework\Homewor
> k 1\Homework_1.log
  log type:  text
 closed on:  16 Oct 2023, 01:32:48
---------------------------------------------------------------------------------------------------------------------------------------
